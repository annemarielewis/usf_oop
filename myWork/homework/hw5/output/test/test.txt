In computer science and information theory, Huffman coding is a lossless data compression algorithm. The technique works by creating a binary tree of nodes. These nodes can be stored in a regular array with the node at index i having children at indices 2i and 2i+1 and parent at index i/2, but this is not the typical representation used for Huffman coding.

David Huffman developed the algorithm as a student at MIT in 1952. The algorithm is widely used in data compression programs, including JPEG image compression and MP3 audio compression. It is also used in fax machines and modems. The Huffman coding scheme is optimal when the probabilities of the symbols are independent and are powers of 1/2.

The algorithm works by first analyzing the frequency of each character in the input. Characters that appear more frequently are assigned shorter codes, while rare characters get longer codes. This variable-length encoding scheme ensures that the most common characters use the fewest bits, resulting in overall compression of the data.

To decode a Huffman-encoded message, you traverse the Huffman tree. Starting at the root, you read bits from the encoded stream. A 0 bit means go left, and a 1 bit means go right. When you reach a leaf node, you output the character stored there and return to the root to decode the next character.
